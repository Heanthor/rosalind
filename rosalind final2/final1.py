from random import sample
from math import log
from copy import deepcopy

filename = "final1.txt"
alphabet = "ACGT"


# calculates total entropy over a profile
def score(profile):
    k = len(profile['A'])
    total_entropy = 0.0

    for i in xrange(k):  # iterate over every column
        tmp = 0.0
        for letter in alphabet:  # every row
            val = profile[letter][i]
            tmp += val * log(val, 2)
        total_entropy += -tmp

    return total_entropy


# calculates the most likely kmer to be generated by this profile, in the given string
def profile_most_kmer(string, profile):
    probabilities = {}
    k = len(profile['A'])

    # for each kmer in string, evaluate its probability using profile
    # then, pick the most probable one from the generated list

    for i in xrange(len(string) - k):
        kmer = string[i: i + k]
        prob = 0.0
        j = 0
        for nuc in kmer:
            prob += profile[nuc][j]
            j += 1
        probabilities[kmer] = (prob, i)

    max_prob = 0.0
    most_probable_kmer = ()
    for kmer, probability in probabilities.items():
        if probability[0] > max_prob:
            most_probable_kmer = (kmer, probability[1])  # (kmer, index)
            max_prob = probability[0]

    # return a tuple containing the kmer and its starting index
    return most_probable_kmer


# generate profile with pseudocounts of motifs
def profile(motifs):
    c = counts(motifs)

    # convert count into profile
    for letter in alphabet:
        for i in xrange(len(c[letter])):
            curr_number = c[letter][i] + 1  # pseudocounts
            c[letter][i] = float(curr_number) / (len(motifs) + 4)
    return c


# generate count(motifs) matrix
def counts(motifs):
    # motifs are same length
    n = len(motifs[0])
    count = {}

    # initialize dicts
    for letter in alphabet:
        count[letter] = [0]*n

    for pos in xrange(n):
        for motif in motifs:
            x = motif[pos]
            count[x][pos] += 1

    return count


def vector_to_strings(strings, vector, k):
    motifs = []
    i = 0
    for starting_index in vector:
        motifs.append(strings[i][starting_index: starting_index + k])
        i += 1
    return motifs


def randomized_motif_search(dna, k, t):
    n = len(dna[0])
    motifs = sample(range(n-k), t)  # starting indices
    best_motifs = [deepcopy(motifs),  score(profile(vector_to_strings(dna, motifs, k)))]

    while True:
        # estimate profile
        profile_motifs = profile(vector_to_strings(dna, motifs, k))

        # calculate most likely motifs
        for j in xrange(t - 1):
            kmer, index = profile_most_kmer(dna[j], profile_motifs)
            motifs[j] = index

        score_motifs = score(profile(vector_to_strings(dna, motifs, k)))
        if score_motifs < best_motifs[1]:
            best_motifs = [motifs, score_motifs]
        else:
            return [vector_to_strings(dna, best_motifs[0], k), best_motifs[1]]  # motifs, and score


# method used to test most probable kmer using rosalind examples
def rosalind_adapter(filename):
    with open(filename, 'r') as f:
        string = f.readline().strip()
        k = f.readline().strip()
        profile = []
        converted_profile = {}

        for i in range(4):
            profile.append(f.readline().strip().split(" "))

        i = 0
        for letter in alphabet:
            converted_profile[letter] = map(float, profile[i])
            i += 1
        print score(converted_profile)

with open(filename, 'r') as f:
    k, t = map(int, f.readline().strip().split())
    strings = []

    while True:
        line = f.readline().strip()
        if not line:
            break
        strings.append(line)

    best_score = k*t  # too high
    best_kmers = []
    all_kmers = set()
    for i in xrange(1000):
        result = randomized_motif_search(strings, k, t)
        if result[1] < best_score:
            best_kmers = result[0]
            for kmer in best_kmers:
                all_kmers.add(kmer)
            best_score = result[1]

    print "\n".join(list(best_kmers))
    #print best_score
